{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Повтор спелл-чекера из \"A Complex Approach to Spellchecking and Autocorrection for Russian\" [Dereza et. al 2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финальный проект по НИСу \"Не мой язык: автоматизированные подходы к изучению интерференции\".  \n",
    "Выполнен студент(-к-)ами группы БКЛ182 *Екатериной Гриневской, Романом Казаковым, Ксенией Петуховой, Вероникой Смилга*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые модули."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import Levenshtein\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import deeppavlov\n",
    "from deeppavlov import configs\n",
    "from deeppavlov import build_model\n",
    "from gensim.models.word2vec import Word2Vec, LineSentence\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "import Levenshtein\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import kenlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные для обучения классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Словарь словарных употреблений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем текст с полными парадигмами для лемм в датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(file_path):\n",
    "    with open(file_path, encoding='windows-1251') as f:\n",
    "        text = f.read()\n",
    "    text = text.replace('€', 'я')\n",
    "    all_forms = []\n",
    "    words = text.split('\\n \\n')\n",
    "    for i in tqdm(words): \n",
    "        spl = i.split('\\n')\n",
    "        for n in range(0, len(spl)):\n",
    "            listi = [spl[0].split(' | ')[0].replace('  ', ''), spl[n].split(' | ')[0].replace('  ', '')]\n",
    "            all_forms.append(listi)\n",
    "    df = pd.DataFrame(all_forms, columns=['lemma', 'forms']).drop_duplicates(keep='first', inplace=False).dropna()\n",
    "    df.to_csv('lemmas-forms.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Русский Учебный Корпус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовываем Русский Учебный Корпус в датафрейм. Оставляем только предложения с орфографическими ошибками и опечатками, токенизируем, каждому токену присваиваем значение 0 (нет ошибки) или 1 (есть ошибка)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_rlc(path_rlc):\n",
    "    df = pd.read_csv(path_rlc)\n",
    "    df = df.dropna(subset=['tags'])\n",
    "    list_space = list(zip(list(df.sentence_id), list(df.tags)))\n",
    "    list_id = []\n",
    "    for id_s, tag in list_space:\n",
    "        if ('Hyphen' in tag) or ('Space' in tag):\n",
    "            list_id.append(id_s)\n",
    "            \n",
    "    for i in list_id:\n",
    "        df = df[df.sentence_id != i]\n",
    "    \n",
    "    df = df[df['tags'].str.match('.*(Ortho|Misspell).*')== True]\n",
    "    list_df = list(zip(list(df.sentence_id), list(df.original_text), list(df.quote)))\n",
    "    sent_id = []\n",
    "    original_texts = []\n",
    "    quotes = []\n",
    "\n",
    "    df_new = pd.DataFrame()\n",
    "    df_new['sentence_id'] = list_df[0]\n",
    "    df_new['original_text'] = list_df[1]\n",
    "    df_new['quote'] = list_df[2]\n",
    "    \n",
    "    list_sent_id = []\n",
    "    list_tokens = []\n",
    "    list_mistake = []\n",
    "    list_token_id = []\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        text = re.sub(r'[^\\w^\\s\\']', '', row['original_text'])\n",
    "        text = text.lower()\n",
    "        text = word_tokenize(text)\n",
    "        for token in text:\n",
    "            list_sent_id.append(row['sentence_id'])\n",
    "            list_tokens.append(token)\n",
    "            list_token_id.append(counter)\n",
    "            counter += 1\n",
    "            if token in row['quote'] or token.upper() in row['quote']:\n",
    "                list_mistake.append(1)\n",
    "            else:\n",
    "                list_mistake.append(0)\n",
    "    \n",
    "    df_final = pd.DataFrame()\n",
    "    df_final['sentence_id'] = list_sent_id\n",
    "    df_final['token'] = list_tokens\n",
    "    df_final['mistake'] = list_mistake\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Серебряный стандарт ГИКРЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из файла с ограниченной выдачей генерального корпуса русского языка получаем датафрейм со столбцами token_id, sentence_id, token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dicts(splitted_doc):\n",
    "    tokens_id = []\n",
    "    sents_id = []\n",
    "    list_of_words = []\n",
    "    sents_count = 200000\n",
    "    tokens_count = 200000\n",
    "    for sent in splitted_doc:\n",
    "        if (sent.startswith('TEXTID'))or(sent.startswith('\\nTEXTID')):\n",
    "            continue\n",
    "        else:\n",
    "            words = sent.split('\\n')\n",
    "            sents_count += 1\n",
    "            for word in words:\n",
    "                word_info = word.split('\\t')\n",
    "                if (len(word_info) > 3)and('#' not in word_info[3]):\n",
    "                    word_dict = {}\n",
    "                    token = word_info[2].replace(' ', '').lower()\n",
    "                    tokens_count += 1\n",
    "                    word_dict['token_id'] = tokens_count\n",
    "                    word_dict['sentence_id'] = sents_count\n",
    "                    word_dict['token'] = token.replace('ё', 'е')\n",
    "                    list_of_words.append(word_dict)\n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для токенов из ГОЛД проверяем, есть ли они в нашем словаре несловарных употреблений. Создаем датафрейм, каждому токену присваеваем 0, если слово есть в словаре (нет ошибки), или 1, если слова нет в словаре (есть ошибка). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_mist(lemmas_forms: pd.DataFrame) -> pd.DataFrame:\n",
    "    lemmas_forms.dropna()\n",
    "    with open('GOLD_1_2_release_demonstrative.txt', encoding = 'utf-8') as f:\n",
    "        init = f.read()\n",
    "    init_splitted = init.split('\\n\\n')\n",
    "    list_of_words = list_of_dicts(init_splitted)\n",
    "    df = pd.DataFrame(list_of_words, columns = ['token_id', 'sentence_id', 'token'])\n",
    "    forms = lemmas_forms['forms'].to_list()\n",
    "    forms = [str(x).replace(' ', '') for x in forms]\n",
    "    print('Маркирую ошибочные слова...')\n",
    "    for word_info in tqdm(list_of_words):\n",
    "        if word_info['token'] in forms:\n",
    "            word_info['mistake'] = 0\n",
    "        else:\n",
    "            word_info['mistake'] = 1\n",
    "    df = pd.DataFrame(list_of_words, columns = ['token_id', 'sentence_id', 'token', 'mistake'])\n",
    "    df.to_csv('gold_df.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем два датафрейма (РУК и GOLD), добавляем в получившийся датафрейм признаки: 1) длина токена; 2) длина контекста(сколько слов в предложении, не считая токен); 3) наличие более двух повторяющихся букв (бинарный признак)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_with_features(df, df2):\n",
    "    new_df = pd.concat([df, df2])\n",
    "    t_id = [i for i in range(len(new_df))]\n",
    "    new_df['token_id'] = t_id\n",
    "    lenght_of_token = []\n",
    "    list_len = []\n",
    "    dict_len = {}\n",
    "    for index, row in new_df.iterrows():\n",
    "        lenght_of_token.append(len(row['token']))\n",
    "        if row['sentence_id'] not in dict_len.keys():\n",
    "            dict_len[row['sentence_id']] = 0\n",
    "        else:\n",
    "            dict_len[row['sentence_id']] += 1\n",
    "\n",
    "    for value in dict_len.values():\n",
    "        for i in range(1, value + 2):\n",
    "            list_len.append(value)\n",
    "            \n",
    "    list_repeat = []\n",
    "    blacklist = []\n",
    "    for index, row in new_df.iterrows():\n",
    "        token = row['token']\n",
    "        rep = 0\n",
    "        black = 0\n",
    "        if len(token) > 2:\n",
    "            for i in range(3, len(token)):\n",
    "                if (token[i] == token[i-1]) and (token[i] == token[i-2]):\n",
    "                    rep = 1\n",
    "        list_repeat.append(rep)\n",
    "        if (re.search(r'[0-9]', token)) or (re.search(r'[^а-яё]', token)) or (len(token) == 1):\n",
    "            black = 1\n",
    "        blacklist.append(black)\n",
    "    \n",
    "    new_df['lenght_of_token'] = lenght_of_token\n",
    "    new_df['amount_context'] = list_len\n",
    "    new_df['repeated_letters'] = list_repeat\n",
    "    new_df['blacklisted'] = blacklist\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *data_for_model()* собирает данные для обучения модели вектороноего представления слов из данных, предоставленные в рамках RuEval2016, данных, предоставленных А. Феногеновой (за что ей большое спасибо), и РУК. Возвращает список предложений из этих источников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_model():\n",
    "    df = pd.read_csv('annotated_texts_rlc.csv').dropna(subset=['original_text', 'corrected_text'])\n",
    "    \n",
    "    all_sents = []\n",
    "    for row in df.itertuples():\n",
    "        all_sents.append(row[3])\n",
    "        all_sents.append(row[4])\n",
    "        \n",
    "    for i in range(1, 4):\n",
    "        for fh in os.listdir(path=f\"./blogsFinal/{i}\"):\n",
    "            with open(f\"./blogsFinal/{i}/{fh}\", encoding='utf-8') as f:\n",
    "                sents = f.readlines()\n",
    "                all_sents.extend(sents)\n",
    "    \n",
    "    with open('source_sents.txt', encoding='utf-8') as f:\n",
    "        sents1 = f.readlines()\n",
    "    all_sents.extend(sents1)\n",
    "    with open('corrected_sents.txt', encoding='utf-8') as f:\n",
    "        sents2 = f.readlines()\n",
    "    all_sents.extend(sents2)\n",
    "    all_sents = list(set(all_sents))\n",
    "    \n",
    "    print('всего предложений для обучения модели:', len(all_sents))\n",
    "    \n",
    "    return all_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *data_to_file(sents)* преобразует список предложений в токенизированные строки и записывает их в файл *for_word2vec.txt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_file(sents):\n",
    "    for s in tqdm(all_sents):\n",
    "        words = [w.lower() for w in word_tokenize(s) if w.isalpha()]\n",
    "        new_sent = ' '.join(words)\n",
    "        with open('for_word2vec.txt', \"a\", encoding=\"utf-8\") as fh:\n",
    "            fh.write(new_sent + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *def model_emb_make(data)* берёт на вход название файла с предложениями и обучает модель *Word2Vec*. Её лучше не запускать, потому что обучение проходит долго, а модель уже сохранена нами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция не используется, так как модель нами уже создана\n",
    "def model_emb_make(data):\n",
    "    model = Word2Vec(LineSentence(data), size=200, window=5, min_count=1, iter=20)\n",
    "    word_vectors = model.wv\n",
    "    word_vectors.save('vectors.kv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *model_emb_use(df_feat)* принимает на вход DataFrame токенов с их признакамит для обучения, описанными выше, и возвращает их с пятым признаком — вектором представления слова. Кроме того, скачивает модель из файлов *vectors.kv* и *vectors.kv.vectors.npy* (!!!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_emb_use(df_feat):\n",
    "    word_vectors = KeyedVectors.load('vectors.kv')\n",
    "    \n",
    "    vects = []\n",
    "    for index, row in tqdm(df_feat.iterrows()):\n",
    "        try:\n",
    "            if row['mistake'] == 0:\n",
    "                vects.append(word_vectors.get_vector(row['token']))\n",
    "            else:\n",
    "                lst_sim = word_vectors.most_similar(row['token'], topn=30)\n",
    "                lst_sim_2 = []\n",
    "                for s_token, s_score in lst_sim:\n",
    "                    if word_vectors.similarity(row['token'], s_token) >= 0.4\\\n",
    "                                    and Levenshtein.ratio(row['token'], s_token) >= 0.3:\n",
    "                        lst_sim_2.append(tuple([s_token, word_vectors.get_vector(s_token)]))\n",
    "                if len(lst_sim_2) == 0:\n",
    "                    vects.append(None)\n",
    "                elif len(lst_sim_2) > 1:\n",
    "                    res = np.stack(tuple([x[1] for x in lst_sim_2]))\n",
    "                    vects.append(np.mean(res, axis = 0))\n",
    "                else:\n",
    "                    vects.append(lst_sim_2[0][1])\n",
    "        except:\n",
    "            vects.append(None)\n",
    "            \n",
    "    df_feat['vectors'] = vects\n",
    "    df_feat = df_feat.replace(to_replace='None', value=np.nan).dropna()\n",
    "    \n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *make_list(array)* принимает объект типа ndarray и преобразует его в list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(array):\n",
    "    return list(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *preproc(df)* принимает на вход DataFrame с признаками для обучения и возвращает тренировочную и тестовую выборки для признаков и классов (0 — правильно, 1 — с ошибкой) в формате list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(df):\n",
    "    df['vectors'] = df['vectors'].apply(make_list)\n",
    "    \n",
    "    features = []\n",
    "    results = []\n",
    "    for row in tqdm(df.itertuples()):\n",
    "        f = []\n",
    "        f.append(row.lenght_of_token)\n",
    "        f.append(row.amount_context)\n",
    "        f.append(row.repeated_letters)\n",
    "        f.append(row.blacklisted)\n",
    "        f.extend(row.vectors)\n",
    "        features.append(f)\n",
    "        results.append(row.mistake)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(features, results, \n",
    "                                                        test_size=0.2, random_state=3)\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *model(train_x, test_x, train_y, test_y)* принимает на вход тренировочную и тестовую выборки для признаков и классов и обучает модель логистической регрессии. Кроме того, печатает отчёт об оценке качества классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_x, test_x, train_y, test_y):\n",
    "    mod = LogisticRegression(random_state=0, max_iter = 200)\n",
    "    mod.fit(train_x, train_y)\n",
    "    target_names=['Правильные', 'Ошибки']\n",
    "    report = metrics.classification_report(test_y, mod.predict(test_x),\n",
    "                                  target_names=target_names)\n",
    "    print(report)\n",
    "    \n",
    "    with open('final_model.pkl','wb') as f:\n",
    "        pickle.dump(mod,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция *main()* собирает все вышеописанные функции, ничего не принимает и ничего не возвращает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    making_df = make_df('Полная_парадигма_Морфология_Орфоэпия_Частотность.txt')\n",
    "    rlc = df_rlc('annotated_texts_rlc.csv')\n",
    "    gold_mist = get_gold_mist(making_df)\n",
    "    features = df_with_features(rlc, gold_mist)\n",
    "    \n",
    "    # data_file_name = data_to_file(data_for_model())\n",
    "    # model_emb_make(data_file_name)\n",
    "    preprocessed = preproc(model_emb_use(features))\n",
    "    model(preprocessed[0], preprocessed[1], preprocessed[2], preprocessed[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181770/181770 [00:15<00:00, 11860.85it/s]\n",
      "  0%|          | 2/20885 [00:00<24:41, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Маркирую ошибочные слова...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20885/20885 [21:51<00:00, 15.92it/s]\n",
      "/Users/romankazakov/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n",
      "169406it [07:34, 372.45it/s]\n",
      "/Users/romankazakov/.local/lib/python3.7/site-packages/pandas/core/missing.py:48: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask = arr == x\n",
      "165989it [00:02, 71237.56it/s]\n",
      "/Users/romankazakov/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Правильные       0.94      0.99      0.96     29928\n",
      "      Ошибки       0.79      0.42      0.55      3270\n",
      "\n",
      "    accuracy                           0.93     33198\n",
      "   macro avg       0.86      0.70      0.75     33198\n",
      "weighted avg       0.92      0.93      0.92     33198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем варианты с пробелом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, получающая все присутствующие в словаре варианты разделения слова на пробелы или дефисы. На вход получает строку (слово), на выходе - список строк с вариантами разделения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_split(word):\n",
    "    cands = []\n",
    "    cands1 = []\n",
    "    for i in range(1, len(word)):\n",
    "        words = []\n",
    "        words.append(''.join(list(word)[:i]))\n",
    "        words.append(''.join(list(word)[i:]))\n",
    "        cands.append(words)\n",
    "    for i in range(1, len(word)):\n",
    "        words = []\n",
    "        words.append(''.join(list(word)[:i]))\n",
    "        words.append(''.join(list(word)[i:]))\n",
    "        w = '-'.join(words)\n",
    "        cands1.append(w)\n",
    "    lemmas_word = pd.read_csv('lemmas-forms.csv').dropna()\n",
    "    forms = lemmas_word['forms'].to_list()\n",
    "    forms = [x.replace(' ', '') for x in forms]\n",
    "    yes = []\n",
    "    for cand in cands:\n",
    "        if cand[0] in forms:\n",
    "            if cand[1] in forms:\n",
    "                yes.append(' '.join(cand))\n",
    "    for cand in cands1:       \n",
    "        if cand in forms:\n",
    "            yes.append(cand)\n",
    "    return yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['кое как', 'кое-как']\n",
      "['потому что']\n"
     ]
    }
   ],
   "source": [
    "print(get_possible_split('коекак'))\n",
    "print(get_possible_split('потомучто'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбираем кандидатов с расстоянием Левенштейна 1, 2 и 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем расстояние Левенштейна слова до всех остальных слов из словаря и берём те, у которых оно равно 1, 2 или 3. На вход функция принимает строку, а на выходе даёт список словарей вида: {1: кандидаты, 2: кандидаты, 3: кандидаты}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(string):\n",
    "    lemmas_forms = pd.read_csv('lemmas-forms.csv')\n",
    "    lemmas_forms.dropna()\n",
    "    forms = lemmas_forms['forms'].to_list()\n",
    "    forms = [str(x).replace(' ', '') for x in forms]\n",
    "    candidates = {'1': [], '2': [], '3': []}\n",
    "    print('Подбираю кандидатов...')\n",
    "    for dict_word in tqdm(forms):\n",
    "        try:\n",
    "            lev_dist = Levenshtein.distance(string, dict_word)\n",
    "            if lev_dist == 1:\n",
    "                candidates['1'].append(dict_word)\n",
    "            elif lev_dist == 2:\n",
    "                candidates['2'].append(dict_word)\n",
    "            elif lev_dist == 3:\n",
    "                candidates['3'].append(dict_word)\n",
    "            else:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 187002/3375170 [00:00<00:03, 934893.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подбираю кандидатов...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375170/3375170 [00:02<00:00, 1287861.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': ['малок', 'малокто', 'малого', 'малого', 'малока', 'малоки', 'малоке', 'малоку', 'малокою', 'малокой', 'малок', 'малого', 'молоко'], '2': ['алого', 'балок', 'балок', 'валок', 'валок', 'валко', 'валко', 'валок', 'галок', 'далеко', 'далеко', 'жалок', 'жалко', 'жалко', 'локо', 'мавок', 'мазок', 'мазок', 'маклок', 'маклока', 'маклоку', 'маклоком', 'маклоке', 'маклоки', 'маклоков', 'маково', 'малой', 'малою', 'малакон', 'малек', 'малька', 'мальку', 'мальком', 'мальке', 'мальки', 'мальков', 'малик', 'малика', 'малику', 'маликом', 'малике', 'малики', 'маликов', 'малка', 'малки', 'малке', 'малку', 'малкою', 'малкой', 'мало', 'малоли', 'малочто', 'малое', 'малому', 'малом', 'малой', 'малому', 'малом', 'малою', 'малое', 'мало', 'малокам', 'малоках', 'малопе', 'малто', 'малому', 'малом', 'малой', 'малою', 'малое', 'мало', 'мамок', 'манок', 'манок', 'манко', 'манко', 'манок', 'марок', 'марок', 'марко', 'масок', 'матако', 'матико', 'маток', 'матово', 'матово', 'маток', 'мачок', 'мелок', 'мелко', 'мелко', 'мелок', 'милок', 'милого', 'милок', 'милого', 'млеко', 'молок', 'молодо', 'молодо', 'молока', 'молоки', 'молоке', 'молоку', 'молокою', 'молокой', 'молок', 'молока', 'молоку', 'молоком', 'молоке', 'мололо', 'молото', 'молочко', 'мшалого', 'мялок', 'палок', 'палоло', 'палого', 'салок', 'талого', 'чалок', 'чалого', 'шалого', 'яблоко'], '3': ['адово', 'алело', 'алло', 'ало', 'алонж', 'алоэ', 'алчно', 'алчно', 'алому', 'алом', 'алой', 'алою', 'алое', 'ало', 'альков', 'алькор', 'амок', 'амока', 'амоку', 'амоком', 'амоке', '*амоки', '*амоков', 'апокоп', 'арок', 'бабок', 'балом', 'балов', 'балка', 'балки', 'балке', 'балку', 'балкою', 'балкой', 'балкон', 'балка', 'балку', 'балком', 'балке', 'балки', 'балков', 'балочка', 'балочки', 'балочке', 'балочку', 'балочкою', 'балочкой', 'балык', 'балыка', 'балыку', 'балыком', 'балыке', 'балыки', 'балыков', 'банок', 'барок', 'барокко', 'басок', 'басок', 'батокс', 'батоно', 'батько', 'бачок', 'башок', 'белок', 'белого', 'белок', 'белого', 'блок', 'блока', 'блоку', 'блоком', 'блоке', 'блоки', 'блоков', 'болото', 'булок', 'былок', 'былого', 'былого', 'валом', 'валов', 'валек', 'валька', 'вальку', 'вальком', 'вальке', 'вальки', 'вальков', 'валик', 'валика', 'валику', 'валиком', 'валике', 'валики', 'валиков', 'валило', 'валено', 'валимо', 'валка', 'валки', 'валке', 'валку', 'валкою', 'валкой', 'валкого', 'валком', 'валкой', 'валкою', 'валкое', 'валка', 'валки', 'валовой', 'валовом', 'валовою', 'валовое', 'валовом', 'валовой', 'валовою', 'валовое', 'валка', 'валку', 'валком', 'валке', 'валки', 'валков', 'валом', 'валяло', 'валяно', 'варок', 'варок', 'ваток', 'велико', 'вилок', 'вилок', 'вмазок', 'волок', 'волока', 'волоку', 'волоком', 'волоке', 'волоки', 'волоков', 'волока', 'волоки', 'волоке', 'волоку', 'волокою', 'волокой', 'волок', 'волокно', 'волокон', 'волоком', 'волок', 'волокло', 'волоку', 'волоки', 'впалого', 'высоко', 'высоко', 'вялого', 'гадок', 'гадко', 'гадко', 'гадово', 'газок', 'галом', 'галов', 'галаго', 'галка', 'галки', 'галке', 'галку', 'галкою', 'галкой', 'гало', 'галоид', 'галоп', 'галопа', 'галопу', 'галопом', 'галопе', 'галопы', 'галопов', 'галопом', 'галофоб', 'галочка', 'галочки', 'галочке', 'галочку', 'галочкою', 'галочкой', 'галоша', 'галоши', 'галоше', 'галошу', 'галош', 'галошка', 'галошки', 'галошке', 'галошку', 'галошкою', 'галошкой', 'галька', 'гальки', 'гальке', 'гальку', 'галькою', 'галькой', 'галек', 'ганок', 'голого', 'гулок', 'гулко', 'гулко', 'давок', 'давок', 'далеком', 'далекой', 'далекою', 'далекое', 'далек', 'далека', 'далеки', 'далека', 'далеке', 'далекое', 'далеком', 'далеро', 'дамок', 'дало', 'далось', 'долото', 'елико', 'елок', 'жабок', 'жако', 'жалело', 'жалето', 'жалило', 'жалено', 'жалимо', 'жалкого', 'жалком', 'жалкой', 'жалкою', 'жалкое', 'жалка', 'жалки', 'жало', 'жалом', 'жалоба', 'жалобы', 'жалобе', 'жалобу', 'жалобой', 'жалобою', 'жалоб', 'жалобь', 'жалобя', 'жалобно', 'жалобно', 'жамок', 'жарок', 'жарок', 'жарко', 'жарко', 'жарок', 'жаток', 'жало', 'жатого', 'жатого', 'жалось', 'жилок', 'жилого', 'жилого', 'задок', 'залом', 'залов', 'залой', 'залою', 'залило', 'залито', 'зало', 'залом', 'залови', 'заловя', 'залог', 'залога', 'залогу', 'залогом', 'залоге', 'залоги', 'залогов', 'заложу', 'заложи', 'заложа', 'залом', 'залома', 'залому', 'заломом', 'заломе', 'заломы', 'заломов', 'заломи', 'заломя', 'залощу', 'залощи', 'залоща', 'замок', 'замок', 'замокло', 'заново', 'зарок', 'зарока', 'зароку', 'зароком', 'зароке', 'зароки', 'зароков', 'заток', 'затока', 'затоку', 'затоком', 'затоке', 'затоки', 'затоков', 'затока', 'затоки', 'затоке', 'затоку', 'затокою', 'затокой', 'заток', 'заулок', 'злого', 'злого', 'золок', 'золотко', 'золото', 'илок', 'илока', 'илоку', 'илоком', 'илоке', 'илоки', 'илоков', 'имало', 'иматого', 'иматого', 'ималось', 'кадок', 'како', 'каково', 'каково', 'какого', 'калом', 'калов', 'калао', 'калека', 'калеки', 'калеке', 'калеку', 'калекою', 'калекой', 'калек', 'калено', 'калика', 'калики', 'калике', 'калику', 'каликою', 'каликой', 'калик', 'калило', 'калено', 'калимо', 'каловом', 'каловой', 'каловою', 'каловое', 'калоед', 'калонг', 'калот', 'калота', 'калоту', 'калотом', 'калоте', 'калоты', 'калотов', 'калоша', 'калоши', 'калоше', 'калошу', 'калош', 'калошка', 'калошки', 'калошке', 'калошку', 'калошкою', 'калошкой', 'калька', 'кальки', 'кальке', 'кальку', 'калькою', 'калькой', 'калек', 'капок', 'карок', 'карько', 'касок', 'каско', 'каток', 'качок', 'клико', 'клок', 'клока', 'клоку', 'клоком', 'клоке', 'клокот', 'колок', 'колок', 'колко', 'колко', 'колок', 'колокол', 'кололо', 'колото', 'котоко', 'лавок', 'лазок', 'лазок', 'лаково', 'лаково', 'лакомо', 'лалом', 'лалов', 'лаловом', 'лаловой', 'лаловою', 'лаловое', 'ланок', 'лапок', 'ласок', 'латок', 'лачок', 'леко', 'лилово', 'лилово', 'ловко', 'ловко', 'лока', 'локи', 'локе', 'локу', 'локою', 'локой', '*локи', '*лок', 'локв', 'локон', 'лоло', 'ломко', 'ломко', 'лоно', 'лоро', 'лото', 'лыко', 'мавка', 'мавки', 'мавке', 'мавку', 'мавкою', 'мавкой', 'магом', 'магов', 'магик', 'магика', 'магику', 'магиком', 'магике', 'магики', 'магиков', 'магнико', 'маго', 'магот', 'магота', 'маготу', 'маготом', 'маготе', 'маготы', 'маготов', 'мадонн', 'маевка', 'маевки', 'маевке', 'маевку', 'маевкою', 'маевкой', 'маевок', 'маетно', 'маетно', 'маечка', 'маечки', 'маечке', 'маечку', 'маечкою', 'маечкой', 'мажор', 'мажора', 'мажору', 'мажором', 'мажоре', 'мажоры', 'мажоров', 'мажорно', 'мажорно', 'мазом', 'мазов', 'мазало', 'мазано', 'мажемо', 'мазик', 'мазика', 'мазику', 'мазиком', 'мазике', 'мазики', 'мазиков', 'мазилок', 'мазка', 'мазки', 'мазке', 'мазку', 'мазкою', 'мазкой', 'мазкого', 'мазком', 'мазкой', 'мазкою', 'мазкое', 'мазло', 'мазлом', 'мазлов', 'мазка', 'мазку', 'мазком', 'мазке', 'мазки', 'мазков', 'мазочка', 'мазочку', 'мазочком', 'мазочке', 'мазочки', 'мазочков', 'майка', 'майки', 'майке', 'майку', 'майкою', 'майкой', 'маек', 'майло', 'майор', 'майора', 'майору', 'майором', 'майоре', 'майоры', 'майоров', 'майорш', 'майском', 'майской', 'майскою', 'майское', 'мак', 'мака', 'маку', 'маком', 'маке', 'маки', 'маков', 'мака', 'макак', 'макака', 'макаку', 'макаком', 'макаке', 'макаки', 'макаков', 'макака', 'макаки', 'макаке', 'макаку', 'макакою', 'макакой', 'макак', 'макао', 'макало', 'макано', 'маки', 'маклак', 'маклака', 'маклаку', 'маклаком', 'маклаке', 'маклаки', 'маклаков', 'маклокам', 'маклоках', 'маков', 'макова', 'макову', 'маковом', 'маковой', 'маковою', 'маковы', 'маковка', 'маковки', 'маковке', 'маковку', 'маковкою', 'маковкой', 'маковок', 'маковом', 'маковой', 'маковою', 'маковое', 'макогон', 'маком', 'макома', 'макому', 'макомом', 'макоме', 'макомы', 'макомов', 'макотр', 'макс', 'мала', 'малы', 'мале', 'малу', 'мал', 'малам', 'малами', 'малах', 'малави', 'малага', 'малаги', 'малаге', 'малагу', 'малагою', 'малагой', 'малаг', 'малаец', 'малайка', 'малайки', 'малайке', 'малайку', 'малайкою', 'малайкой', 'малаек', 'малакона', 'малакону', 'малаконе', 'малаконы', 'малат', 'малата', 'малату', 'малатом', 'малате', 'малаты', 'малатов', 'малюют', 'малюю', 'малюет', 'малюем', 'малюй', 'малюем', 'малюемо', 'малюя', 'малькам', 'мальках', 'маленько', 'маленько', 'малец', 'мальца', 'мальцу', 'мальцом', 'мальце', 'мальцы', 'мальцов', 'малиец', 'малийка', 'малийки', 'малийке', 'малийку', 'малийкою', 'малийкой', 'малиек', 'маликам', 'маликах', 'малина', 'малины', 'малине', 'малину', 'малиной', 'малиною', 'малин', 'малинка', 'малинки', 'малинке', 'малинку', 'малинкою', 'малинкой', 'малинок', 'малинке', 'малиново', 'малица', 'малицы', 'малице', 'малицу', 'малиц', 'малкам', 'малках', 'малогде', 'малокакой', 'маловато', 'маловат', 'маловато', 'маловер', 'маловес', 'маловеско', 'маловязко', 'малодоек', 'малым', 'малоежка', 'малоежки', 'малоежке', 'малоежку', 'малоежкою', 'малоежкой', 'малым', 'малая', 'малую', 'малые', 'малых', 'малыми', 'мал', 'мала', 'малы', 'малоками', 'малоросс', 'малорус', 'малость', 'малости', 'малый', 'малым', 'малая', 'малую', 'малые', 'малых', 'малыми', 'мал', 'мала', 'малы', 'малыш', 'малыша', 'малышу', 'малышом', 'малыше', 'малыши', 'малышка', 'малышки', 'малышке', 'малышку', 'малышкою', 'малышкой', 'малышок', 'малышка', 'малышку', 'малышком', 'малышке', 'малышки', 'малышков', 'мальборо', 'мальва', 'мальвы', 'мальве', 'мальву', 'мальвой', 'мальвою', 'мальв', 'малье', 'малья', 'малью', 'мальем', 'мальм', 'мальма', 'мальму', 'мальмом', 'мальме', 'мальма', 'мальмы', 'мальме', 'мальму', 'мальмой', 'мальмою', 'мальм', 'мальтоз', 'малютка', 'малютки', 'малютке', 'малютку', 'малюткою', 'малюткой', 'малюток', 'малявка', 'малявки', 'малявке', 'малявку', 'малявкою', 'малявкой', 'малявок', 'маляр', 'маляра', 'маляру', 'маляром', 'маляре', 'маляры', 'маляров', 'малярю', 'малярь', 'маляря', 'малярка', 'малярки', 'малярке', 'малярку', 'маляркою', 'маляркой', 'малярок', 'малярш', 'мамой', 'мамою', 'мамбо', 'мамино', 'мамка', 'мамки', 'мамке', 'мамку', 'мамкою', 'мамкой', 'мамлюк', 'мамлюка', 'мамлюку', 'мамлюком', 'мамлюке', 'мамлюки', 'мамлюков', 'мамон', 'мамона', 'мамону', 'мамоном', 'мамоне', 'мамона', 'мамоны', 'мамоне', 'мамону', 'мамоной', 'мамоною', 'мамон', 'мамонт', 'мамочка', 'мамочки', 'мамочке', 'мамочку', 'мамочкою', 'мамочкой', 'мамочки', 'маной', 'маною', 'манго', 'манено', 'маниок', 'маниока', 'маниоку', 'маниоком', 'маниоке', 'маниоки', 'маниоков', 'маниока', 'маниоки', 'маниоке', 'маниоку', 'маниокою', 'маниокой', 'манило', 'манено', 'манимо', 'манка', 'манки', 'манке', 'манку', 'манкою', 'манкой', 'манки', 'манкого', 'манком', 'манкой', 'манкою', 'манкое', 'манка', 'манки', 'манного', 'мано', 'манка', 'манку', 'манком', 'манке', 'манки', 'манков', 'манор', 'манора', 'манору', 'манором', 'маноре', 'маноры', 'маноров', 'манто', 'маори', 'маром', 'маров', 'марой', 'марою', 'марало', 'марано', 'марго', 'марево', 'марило', 'марка', 'марки', 'марке', 'марку', 'маркою', 'маркой', 'маркого', 'марком', 'маркой', 'маркою', 'маркое', 'марка', 'марки', 'маркс', 'марокен', 'марочка', 'марочки', 'марочке', 'марочку', 'марочкою', 'марочкой', 'марсово', 'маска', 'маски', 'маске', 'маску', 'маскою', 'маской', 'маскон', 'маслено', 'маслило', 'маслено', 'маслимо', 'масличко', 'маслишко', 'масло', 'маслом', 'маслобой', 'маслобоя', 'маслобою', 'маслобое', 'маслобои', 'маслотоп', 'маслюк', 'маслюка', 'маслюку', 'маслюком', 'маслюке', 'маслюки', 'маслюков', 'масляно', 'масон', 'масона', 'масону', 'масоном', 'масоне', 'масоны', 'масонов', 'масонка', 'масонки', 'масонке', 'масонку', 'масонкою', 'масонкой', 'масонок', 'масочка', 'масочки', 'масочке', 'масочку', 'масочкою', 'масочкой', 'матом', 'матов', 'матеро', 'матеро', 'матка', 'матки', 'матке', 'матку', 'маткою', 'маткой', 'матлот', 'матлота', 'матлоту', 'матлотом', 'матлоте', 'матлоты', 'матлотов', 'матовом', 'матовой', 'матовою', 'матовое', 'матов', 'матова', 'матовы', 'матка', 'матку', 'матком', 'матке', 'матки', 'матков', 'матом', 'маточка', 'маточки', 'маточке', 'маточку', 'маточкою', 'маточкой', 'матюк', 'матюка', 'матюку', 'матюком', 'матюке', 'матюки', 'матюков', 'матюком', 'мафиозо', 'махом', 'махов', 'махалок', 'махало', 'махало', 'маховой', 'маховом', 'маховою', 'маховое', 'маховом', 'маховой', 'маховою', 'маховое', 'махом', 'махорка', 'махорки', 'махорке', 'махорку', 'махоркою', 'махоркой', 'махотка', 'махотки', 'махотке', 'махотку', 'махоткою', 'махоткой', 'махоток', 'махрово', 'махрово', 'мацой', 'мацою', 'мацони', 'мачка', 'мачку', 'мачком', 'мачке', 'мачки', 'мачков', 'машона', 'маяк', 'маяка', 'маяку', 'маяком', 'маяке', 'маяки', 'маяков', 'маятно', 'маятно', 'маяло', 'маяно', 'маемого', 'маемого', 'маемо', 'маялось', 'маячок', 'маячка', 'маячку', 'маячком', 'маячке', 'маячки', 'маячков', 'мглой', 'мглою', 'медово', 'медово', 'медок', 'мелом', 'мелов', 'мелево', 'мелело', 'мелило', 'мелено', 'мелимо', 'мелкого', 'мелком', 'мелкой', 'мелкою', 'мелкое', 'мелка', 'мелки', 'мелкот', 'меловой', 'меловом', 'меловою', 'меловое', 'мелод', 'мелода', 'мелоду', 'мелодом', 'мелоде', 'мелоды', 'мелодов', 'мелка', 'мелку', 'мелком', 'мелке', 'мелки', 'мелков', 'мелос', 'мелоса', 'мелосу', 'мелосом', 'мелосе', 'мелосы', 'мелосов', 'мелочу', 'мелочи', 'мелоча', 'мелочно', 'мелочно', 'мелочь', 'мелочи', 'мельк', 'мельком', 'менок', 'мерзко', 'мерзко', 'мерок', 'мело', 'мелось', 'меток', 'меток', 'метко', 'метко', 'мешалок', 'мешок', 'мивок', 'мивока', 'мивоку', 'мивоком', 'мивоке', 'мивоки', 'мивоков', 'мигалок', 'милом', 'милов', 'милело', 'милка', 'милки', 'милке', 'милку', 'милкою', 'милкой', 'мило', 'милое', 'милому', 'милом', 'милорд', 'милочка', 'милочки', 'милочке', 'милочку', 'милочкою', 'милочкой', 'милому', 'милом', 'милой', 'милою', 'милое', 'мило', 'мирок', 'мисок', 'младого', 'младо', 'млека', 'млеку', 'млеком', 'млеке', 'млело', 'много', 'мокко', 'мок', 'мокло', 'мокой', 'мокоя', 'мокою', 'мокое', 'мокои', 'мокро', 'мокр', 'мокро', 'мокш', 'молом', 'молов', 'молило', 'молено', 'молимо', 'молка', 'молки', 'молке', 'молку', 'молкою', 'молкой', 'молкло', 'моложу', 'молоди', 'молодя', 'молодка', 'молодки', 'молодке', 'молодку', 'молодкою', 'молодкой', 'молодок', 'моложе', 'молодой', 'молодом', 'молодою', 'молодое', 'молод', 'молода', 'молоды', 'моложе', 'молодь', 'молоди', 'молокам', 'молоках', 'молокан', 'молокан', '*молоки', '*молок', 'молот', 'молота', 'молоту', 'молотом', 'молоте', 'молоты', 'молотов', 'молочу', 'молоти', 'молотя', 'молоток', 'молотка', 'молотку', 'молотком', 'молотке', 'молотки', 'молотков', 'молотом', 'молотой', 'молотою', 'молотое', 'молоть', 'молол', 'молола', 'мололи', 'молотом', 'молотой', 'молотою', 'молотое', 'молотом', 'молот', 'молота', 'молоты', 'молох', 'молоха', 'молоху', 'молохом', 'молохе', 'молохи', 'молохов', 'молочка', 'молочку', 'молочком', 'молочке', 'молочки', 'молочков', 'молчком', 'молчок', 'молчка', 'молчку', 'молчком', 'молчке', 'молчки', 'молчков', 'монокок', 'моро', 'морозко', 'морок', 'морока', 'мороку', 'мороком', 'мороке', 'мороки', 'мороков', 'морока', 'мороки', 'мороке', 'мороку', 'морокою', 'морокой', 'морок', 'моталок', 'моток', 'моток', 'мохо', 'мочалок', 'мулом', 'мулов', 'мулек', 'мулька', 'мульку', 'мульком', 'мульке', 'мульки', 'мульков', 'мульк', 'мулька', 'мульку', 'мульком', 'мульке', 'мурок', 'мчало', 'мчалось', 'мшавого', 'мшалому', 'мшалом', 'мшалой', 'мшалою', 'мшалое', 'мшанок', 'мшаного', 'мылило', 'мылено', 'мылимо', 'мылкого', 'мылком', 'мылкой', 'мылкою', 'мылкое', 'мыло', 'мылом', 'мысок', 'мыло', 'мытого', 'мытого', 'мылось', 'мягок', 'мягко', 'мягко', 'мяклого', 'мялка', 'мялки', 'мялке', 'мялку', 'мялкою', 'мялкой', 'мяло', 'мялом', 'мяско', 'мясок', 'мятого', 'мяло', 'мятого', 'мятого', 'мялось', 'набок', 'напока', 'напокое', 'наслово', 'наушко', 'набок', 'навок', 'наглого', 'нагого', 'наголо', 'наилок', 'накосо', 'налом', 'налево', 'налито', 'налило', 'налито', 'налицо', 'налови', 'наловя', 'налог', 'налога', 'налогу', 'налогом', 'налоге', 'налоги', 'налогов', 'наложу', 'наложи', 'наложа', 'налой', 'налоя', 'налою', 'налоем', 'налое', 'налои', 'налоев', 'налоям', 'налоях', 'наломи', 'налощу', 'налощи', 'налоща', 'намок', 'намокло', 'нанок', 'наново', 'нароком', 'натонко', 'неловко', 'неловко', 'немалого', 'немалого', 'облако', 'облого', 'око', 'олово', 'опалок', 'опалого', 'отлого', 'падок', 'падко', 'пазок', 'палом', 'палов', 'палило', 'палено', 'палимо', 'палка', 'палки', 'палке', 'палку', 'палкою', 'палкой', 'палочка', 'палочки', 'палочке', 'палочку', 'палочкою', 'палочкой', 'палому', 'палом', 'палой', 'палою', 'палое', 'пальто', 'папок', 'парок', 'парко', 'парок', 'пасока', 'пасоки', 'пасоке', 'пасоку', 'пасокою', 'пасокой', 'пасок', 'пасомо', 'пало', 'патока', 'патоки', 'патоке', 'патоку', 'патокою', 'патокой', 'паток', 'пилок', 'плоско', 'плоско', 'плохо', 'плохо', 'полок', 'полого', 'полок', 'пололо', 'полото', 'полого', 'пылок', 'пылко', 'пылко', 'пялок', 'разок', 'рало', 'ралом', 'рамок', 'ранок', 'рачок', 'рококо', 'савок', 'садок', 'садко', 'садок', 'салака', 'салаки', 'салаке', 'салаку', 'салакою', 'салакой', 'салак', 'салило', 'салено', 'салимо', 'салка', 'салки', 'салке', 'салку', 'салкою', 'салкой', 'сало', 'салом', 'саловом', 'саловой', 'саловою', 'саловое', 'салол', 'салола', 'салолу', 'салолом', 'салоле', 'салолы', 'салолов', 'салон', 'салона', 'салону', 'салоном', 'салоне', 'салоны', 'салонов', 'салоп', 'салопа', 'салопу', 'салопом', 'салопе', 'салопы', 'салопов', 'салотоп', 'салочка', 'салочки', 'салочке', 'салочку', 'салочкою', 'салочкой', 'сальдо', 'сально', 'сальто', 'самого', 'самок', 'самуко', 'самого', 'санок', 'сапок', 'сачок', 'свалок', 'силок', 'скалок', 'склока', 'склоки', 'склоке', 'склоку', 'склокою', 'склокой', 'склок', 'слово', 'смазок', 'смелого', 'смолок', 'смололо', 'смолото', 'солоно', 'солок', 'солок', 'солко', 'солоно', 'счалок', 'таково', 'такого', 'такого', 'талом', 'талов', 'талик', 'талика', 'талику', 'таликом', 'талике', 'талики', 'таликов', 'таловом', 'таловой', 'таловою', 'таловое', 'талон', 'талона', 'талону', 'талоном', 'талоне', 'талоны', 'талонов', 'талому', 'талом', 'талой', 'талою', 'талое', 'тало', 'тальк', 'талька', 'тальку', 'тальком', 'тальке', 'талька', 'тальки', 'тальке', 'тальку', 'талькою', 'талькой', 'талек', 'талькоз', 'танок', 'тапок', 'тасок', 'таток', 'таялок', 'телок', 'телок', 'толико', 'толока', 'толоки', 'толоке', 'толоку', 'толокою', 'толокой', 'толок', 'толокно', 'толок', 'только', 'тулово', 'увалок', 'удалого', 'удалого', 'умалило', 'умалено', 'умаляло', 'умелого', 'упалого', 'уралок', 'утлого', 'ушлого', 'фалом', 'фалов', 'фаловом', 'фаловой', 'фаловою', 'фаловое', 'фасок', 'фиалок', 'флокс', 'халой', 'халою', 'хамок', 'хамово', 'хапок', 'хаток', 'хилого', 'холок', 'цапок', 'целок', 'целого', 'целого', 'чадочко', 'чаишко', 'чакобо', 'чалом', 'чалов', 'чалило', 'чалено', 'чалимо', 'чалка', 'чалки', 'чалке', 'чалку', 'чалкою', 'чалкой', 'чалому', 'чалом', 'чалой', 'чалою', 'чалое', 'чало', 'чарок', 'часок', 'чахлого', 'челок', 'чулок', 'шавок', 'шажок', 'шалой', 'шалою', 'шалело', 'шалило', 'шало', 'шалон', 'шалона', 'шалону', 'шалоном', 'шалоне', 'шалоны', 'шалонов', 'шалот', 'шалота', 'шалоту', 'шалотом', 'шалоте', 'шалоты', 'шалотов', 'шалому', 'шалом', 'шалой', 'шалою', 'шалое', 'шалька', 'шальки', 'шальке', 'шальку', 'шалькою', 'шалькой', 'шалек', 'шалькой', 'шапок', 'шарок', 'шаток', 'шатко', 'шатко', 'широко', 'широко', 'шлока', 'шлоки', 'шлоке', 'шлоку', 'шлокою', 'шлокой', 'шлок', 'шматок', 'щаного', 'щелок', 'щелок', 'щелока', 'щелоку', 'щелоком', 'щелоке', 'щелоки', 'щелоков', 'эолово', 'юлок', 'яблока', 'яблоку', 'яблоком', 'яблоке', 'яблоки', 'яблок', 'яблочко', 'ямалском', 'ямалской', 'ямалскою', 'ямалское']}\n"
     ]
    }
   ],
   "source": [
    "print(get_candidates('малоко'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В силу того, что у нас не было возможности воссоздать корректор полностью (но части получилось (см. две функции выше)) из-за отсутствия подходящей языковой модели. Мы воспользовались подготовленными моделями от *deeppavlov* Левенштейна и Brill & Moore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-23 20:00:52.545 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/vocabs/russian_words_vocab.dict.gz to /Users/romankazakov/.deeppavlov/downloads/russian_words_vocab.dict.gz\n",
      "100%|██████████| 10.7M/10.7M [00:05<00:00, 1.87MB/s]\n",
      "2020-12-23 20:00:58.336 INFO in 'deeppavlov.core.data.utils'['utils'] at line 268: Extracting /Users/romankazakov/.deeppavlov/downloads/russian_words_vocab.dict.gz archive into /Users/romankazakov/.deeppavlov/downloads/vocabs\n",
      "2020-12-23 20:00:58.620 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/lang_models/ru_wiyalen_no_punkt.arpa.binary.gz to /Users/romankazakov/.deeppavlov/downloads/ru_wiyalen_no_punkt.arpa.binary.gz\n",
      "100%|██████████| 3.26G/3.26G [31:58<00:00, 1.70MB/s]   \n",
      "2020-12-23 20:32:57.49 INFO in 'deeppavlov.core.data.utils'['utils'] at line 268: Extracting /Users/romankazakov/.deeppavlov/downloads/ru_wiyalen_no_punkt.arpa.binary.gz archive into /Users/romankazakov/.deeppavlov/downloads/language_models\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/romankazakov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/romankazakov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /Users/romankazakov/nltk_data...\n",
      "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /Users/romankazakov/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2020-12-23 20:33:31.319 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /Users/romankazakov/.deeppavlov/downloads/vocabs/russian_words_vocab.dict]\n",
      "2020-12-23 20:35:18.695 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/error_model.tar.gz to /Users/romankazakov/.deeppavlov/error_model.tar.gz\n",
      "100%|██████████| 5.36M/5.36M [00:02<00:00, 1.95MB/s]\n",
      "2020-12-23 20:35:21.570 INFO in 'deeppavlov.core.data.utils'['utils'] at line 268: Extracting /Users/romankazakov/.deeppavlov/error_model.tar.gz archive into /Users/romankazakov/.deeppavlov/models\n",
      "2020-12-23 20:35:29.255 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/lang_models/ru_wiyalen_no_punkt.arpa.binary.gz download because of matching hashes\n",
      "2020-12-23 20:35:29.573 INFO in 'deeppavlov.vocabs.typos'['typos'] at line 56: Trying to build a dictionary in /Users/romankazakov/.deeppavlov/downloads/vocabs/russian_words_vocab\n",
      "2020-12-23 20:35:29.575 INFO in 'deeppavlov.vocabs.typos'['typos'] at line 122: Downloading russian vocab from https://github.com/danakt/russian-words/\n",
      "2020-12-23 20:36:37.465 INFO in 'deeppavlov.vocabs.typos'['typos'] at line 81: built\n",
      "2020-12-23 20:36:44.570 INFO in 'deeppavlov.models.spelling_correction.brillmoore.error_model'['error_model'] at line 236: loading error_model from `/Users/romankazakov/.deeppavlov/models/error_model/error_model_ru.tsv`\n"
     ]
    }
   ],
   "source": [
    "lev = build_model(deeppavlov.configs.spelling_correction.levenshtein_corrector_ru, download=True)\n",
    "brill = build_model(deeppavlov.configs.spelling_correction.brillmoore_kartaslov_ru, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерфейс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция принимает на вход список токенов введенного предложения из функции *search()*, которая присваивает признаки для обучения для каждого из токенов и возвращает датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_predict_feat(list_of_tokens):\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['token'] = list_of_tokens\n",
    "    lenght_of_token = []\n",
    "    for index, row in new_df.iterrows():\n",
    "        lenght_of_token.append(len(row['token']))\n",
    "    list_repeat = []\n",
    "    blacklist = []\n",
    "    \n",
    "    word_vectors = KeyedVectors.load('vectors.kv')\n",
    "    vects = []\n",
    "    \n",
    "    for index, row in new_df.iterrows():\n",
    "        token = row['token']\n",
    "        rep = 0\n",
    "        black = 0\n",
    "        if len(token) > 2:\n",
    "            for i in range(3, len(token)):\n",
    "                if (token[i] == token[i-1]) and (token[i] == token[i-2]):\n",
    "                    rep = 1\n",
    "        list_repeat.append(rep)\n",
    "        if (re.search(r'[0-9]', token)) or (re.search(r'[^а-яё]', token)) or (len(token) == 1):\n",
    "            black = 1\n",
    "        blacklist.append(black)\n",
    "        try:\n",
    "            vects.append(word_vectors.get_vector(token))\n",
    "        except KeyError:\n",
    "            vects.append([None])\n",
    "    \n",
    "    new_df['lenght_of_token'] = lenght_of_token\n",
    "    new_df['amount_context'] = [(len(list_of_tokens) - 1) for i in range(len(list_of_tokens))]\n",
    "    new_df['repeated_letters'] = list_repeat\n",
    "    new_df['blacklisted'] = blacklist\n",
    "    new_df['vectors'] = vects\n",
    "    new_df['vectors'] = new_df['vectors'].apply(make_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принимает токен, если он есть в списке частотных ошибок русского языка, полученных с помощью ручной обработки, и датафрейм из функции *search()* и возвращает кортеж вида (токен, 1 (есть ошибка), исправление). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_popular(word, df):\n",
    "    for i in range(len(df)):\n",
    "        if df['original'].iloc[i] == word:\n",
    "            correction = df['corrected'].iloc[i]\n",
    "    return word, 1, correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразует список типа [float, float, float, float, list] в список, состоящий из первых четырех элементов и всех элементов из list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_list(list_df):\n",
    "    new_list = list_df[0:4]\n",
    "    new = list_df[4]\n",
    "    new_list.extend(new)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главная функция, предлагающая пользователю ввести предложение для исправления и выбрать модель, с помощью которой функция исправит опечатки. Возвращает датафрейм со столбцами: токен, наличие ошибки, исправление. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search():\n",
    "    df_hype = pd.read_csv('popular_mistakes.tsv', sep='\\t', header=0)\n",
    "    sentence = input('Введите предложение: ')\n",
    "    algo = int(input('Выберите алгоритм: 0 - Левенштейн, 1 - Brill & Moore '))\n",
    "    sentence =  re.sub(r'[^\\w^\\s\\']', '', sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = word_tokenize(sentence)\n",
    "    no_repeated = []\n",
    "    df = for_predict_feat(sentence)\n",
    "    corrections = []\n",
    "    \n",
    "    for token in sentence:\n",
    "        if len(token) > 2:\n",
    "            token = re.compile(r'(.)\\1{2,}').sub(r'\\1', token)   \n",
    "        no_repeated.append(token)\n",
    "     \n",
    "    great_result = []\n",
    "    with open('final_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    for token in no_repeated:\n",
    "        if token in list(df_hype['original']):\n",
    "            token, result, correction = correct_popular(token, df_hype)\n",
    "        else:\n",
    "            try:\n",
    "                result = model.predict([extend_list(df.loc[df['token'] == token, \n",
    "                                                  ['lenght_of_token', \n",
    "                                                   'amount_context', \n",
    "                                                   'repeated_letters', \n",
    "                                                   'blacklisted', \n",
    "                                                   'vectors']].values.tolist()[0])])\n",
    "            except:\n",
    "                result = [1] \n",
    "            if result == [1]:\n",
    "                if algo == 0:\n",
    "                    correction = lev([token])[0]\n",
    "                else:\n",
    "                    correction = brill([token])[0]\n",
    "            else: \n",
    "                correction = token\n",
    "            \n",
    "        great_result.append(int(result[0]))\n",
    "        corrections.append(str(correction))\n",
    "    \n",
    "    \n",
    "    quote = pd.DataFrame()\n",
    "    quote['token'] = sentence\n",
    "    quote['mistake'] = great_result\n",
    "    quote['correction'] = corrections\n",
    "    \n",
    "    return quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инструкция для пользователя: введите предложение на русском языке, а затем введите номер модели. Запрустите функцию ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите предложение: Малако вкусное в моём халадилнике.\n",
      "Выберите алгоритм: 0 - Левенштейн, 1 - Brill & Moore 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>mistake</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>малако</td>\n",
       "      <td>1</td>\n",
       "      <td>молоко</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вкусное</td>\n",
       "      <td>0</td>\n",
       "      <td>вкусное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>в</td>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>моём</td>\n",
       "      <td>0</td>\n",
       "      <td>моём</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>халадилнике</td>\n",
       "      <td>1</td>\n",
       "      <td>холодильнике</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  mistake    correction\n",
       "0       малако        1        молоко\n",
       "1      вкусное        0       вкусное\n",
       "2            в        0             в\n",
       "3         моём        0          моём\n",
       "4  халадилнике        1  холодильнике"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите предложение: Малако вкусное в моём халадилнике.\n",
      "Выберите алгоритм: 0 - Левенштейн, 1 - Brill & Moore 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>mistake</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>малако</td>\n",
       "      <td>1</td>\n",
       "      <td>малакон</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вкусное</td>\n",
       "      <td>0</td>\n",
       "      <td>вкусное</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>в</td>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>моём</td>\n",
       "      <td>0</td>\n",
       "      <td>моём</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>халадилнике</td>\n",
       "      <td>1</td>\n",
       "      <td>халадилнике</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  mistake   correction\n",
       "0       малако        1      малакон\n",
       "1      вкусное        0      вкусное\n",
       "2            в        0            в\n",
       "3         моём        0         моём\n",
       "4  халадилнике        1  халадилнике"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, модель на основе расстояния Левенштейна работает плохо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите предложение: Призумпция невиновности.\n",
      "Выберите алгоритм: 0 - Левенштейн, 1 - Brill & Moore 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>mistake</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>призумпция</td>\n",
       "      <td>1</td>\n",
       "      <td>презумпция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>невиновности</td>\n",
       "      <td>0</td>\n",
       "      <td>невиновности</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  mistake    correction\n",
       "0    призумпция        1    презумпция\n",
       "1  невиновности        0  невиновности"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите предложение: Призумпция невиновности.\n",
      "Выберите алгоритм: 0 - Левенштейн, 1 - Brill & Moore 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>mistake</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>призумпция</td>\n",
       "      <td>1</td>\n",
       "      <td>презумпция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>невиновности</td>\n",
       "      <td>0</td>\n",
       "      <td>невиновности</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  mistake    correction\n",
       "0    призумпция        1    презумпция\n",
       "1  невиновности        0  невиновности"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите предложение: Ооооооооооччень крутой проэкт у наз.\n",
      "Выберите алгоритм: 0 - Левенштейн, 1 - Brill & Moore 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>mistake</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ооооооооооччень</td>\n",
       "      <td>1</td>\n",
       "      <td>очень</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>крутой</td>\n",
       "      <td>0</td>\n",
       "      <td>крутой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>проэкт</td>\n",
       "      <td>0</td>\n",
       "      <td>проэкт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>у</td>\n",
       "      <td>0</td>\n",
       "      <td>у</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>наз</td>\n",
       "      <td>0</td>\n",
       "      <td>наз</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  mistake correction\n",
       "0  ооооооооооччень        1      очень\n",
       "1           крутой        0     крутой\n",
       "2           проэкт        0     проэкт\n",
       "3                у        0          у\n",
       "4              наз        0        наз"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите предложение: Ооооооооооччень крутой проэкт у наз.\n",
      "Выберите алгоритм: 0 - Левенштейн, 1 - Brill & Moore 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>mistake</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ооооооооооччень</td>\n",
       "      <td>1</td>\n",
       "      <td>очень</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>крутой</td>\n",
       "      <td>0</td>\n",
       "      <td>крутой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>проэкт</td>\n",
       "      <td>0</td>\n",
       "      <td>проэкт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>у</td>\n",
       "      <td>0</td>\n",
       "      <td>у</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>наз</td>\n",
       "      <td>0</td>\n",
       "      <td>наз</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  mistake correction\n",
       "0  ооооооооооччень        1      очень\n",
       "1           крутой        0     крутой\n",
       "2           проэкт        0     проэкт\n",
       "3                у        0          у\n",
       "4              наз        0        наз"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество работы модели будет представлено на защите проекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
